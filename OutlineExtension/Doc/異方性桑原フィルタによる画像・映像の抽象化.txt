https://www.kyprianidis.com/p/pg2009/jkyprian-pg2009.pdf

概要
カラー画像や動画を絵画的な抽象画に変換するノンフォトリアリスティックレンダリング技術を紹介する。これは、特徴の局所形状に適応した桑原フィルタの一般化に基づいている、桑原フィルタの一般化に基づいている。従来のエッジ保存フィルタとは異なり、我々のフィルタはを生成する。従来のペインティングアルゴリズムとは異なり、余分な処理を行うことなく、時間的にコヒーレントな映像抽象化を生成する。
本手法のGPU実装はリアルタイムで映像を処理する。その結果は、漫画を持つが、油絵に見られるような方向情報も示す。
カテゴリとサブジェクト記述子（ACM CCSによる）： I.3.3 [コンピュータグラフィックス]： 画像生成
表示アルゴリズム

1. はじめに
フォトリアリスティックな描写には、意図した情報を伝えるために必要以上の情報が含まれていることが多い。
そのためアーティストは、効果的なビジュアル・コミュニケーションのために、ディテールを取り除き、抽象化を用いるのが一般的である。画像や動画から様式化された抽象画を自動的に作成する典型的なアプローチは、
エッジ保存フィルタの使用である。画像の抽象化に使われるエッジ保存フィルタの一般的な例としては、バイラテラル・フィルタ[TM98]や平均シフト[CM02]がある。
どちらも高コントラストのエッジを保持しながら低コントラスト領域を平滑化するため、高コントラスト画像では、使用する閾値のために、抽象化が行われなかったり、関連情報が削除されたりして失敗することがあります（図9）。
また、低コントラスト画像では、一般的に情報が除去されすぎて失敗することが多い（図10）。この限界を克服するエッジ保存フィルタに桑原フィルタ[KHEK76]がある。
局所領域の平坦化に基づく桑原フィルタは、高コントラスト領域のディテールを適切に除去すると同時に、低コントラスト領域の形状境界を保護する。
そのため、画像全体の抽象度をほぼ一定に保ちながら、全体的に絵画調に仕上げることができる。
残念ながら、桑原フィルタはノイズがあると不安定で、ブロック・アーチファクトに悩まされる。オリジナルの桑原フィルタを改良するために、いくつかの拡張や修正が提案されている。
Papariら[PPC07]による最新の研究では、新しい重み付け窓と新しい組み合わせ規則を導入している。

　これによって出力品質が大幅に改善されたとしても、クラスタリングアーチファクトはまだ目立つ。
本研究では、フィルタの形状、スケール、向きを入力の局所構造に適応させることで、クラスタリングアーチファクトを除去する桑原フィルタの一般化を提示する（図3）。
このようにフィルタを局所構造に適応させることで、方向性のある画像の特徴がよりよく保存され強調される。
その結果、全体的にエッジがシャープになり、より特徴を生かした絵画的な効果が得られる。
したがって、我々のアプローチは、典型的な絵画的レンダリングアルゴリズム[Lit97,Her03,HE04]に代わる興味深いものである。
これらもディテールを除去しますが、シャープなエッジと表面の完全性を保持できないことがよくあります。
さらに、個々のブラシストロークをグラフィカルプリミティブとして扱う必要があるため、一般的に処理速度が遅い。

　また、動画を処理する場合、ストロークの時間的コヒーレンスを維持するために、高価な動き推定を必要とする。
対照的に、我々のアプローチは、ストロークを処理するための高度なメカニズムを必要とせず、ビデオの動き推定なしで優れた時間的コヒーレンスを示す。
我々のアプローチのGPU実装は、リアルタイムでビデオを処理する。


2. 関連作品
エッジを保存する非線形フィルタは、数十年前から活発な研究テーマとなっている。この分野の古典的なフィルタは、よく知られた桑原フィルタ[KHEK76]とその亜種[TT77,NM79]である。
これらのフィルタの一般的な考え方は、入力画素を分散が最小の部分領域の平均で置き換えることである。変種は部分領域の定義方法が異なる。
桑原フィルターと富田・辻フィルターは矩形の部分領域を用い、 長尾・松山フィルターは回転した細長いバーマスクを用いる。矩形部分領域の使用は出力に目に見えるアーチファクトをもたらす。
さらに、ノイズが存在したり、部分領域が同じ分散を持つ場合、部分領域選択プロセスは不安定になる。
その結果、ランダムにサブ領域が選択され、対応するアーチファクトが発生する（図2(b)）。
桑原フィルターの限界に関する詳細な議論は[PPC07]にあります。
Van den Boomgaard [vdB02]はボックスフィルタをガウシアンフィルタで置き換えたが、これはわずかな改善しかもたらさない(図2(c))。
最近、Papariら[PPC07]は桑原フィルタの一般化された変形を発表した。彼らは最小標準偏差基準の限界を克服するために新しい基準を定義した。
単一の部分領域を選択する代わりに、部分領域の平均の重み付き和として結果を定義している。
重みは部分領域の分散に基づいて定義される。図2(d)に見られるように、この結果、領域の境界がより滑らかになり、アーチファクトが少なくなる。
これをさらに改善するために、Papariらは円盤のセクタである部分領域に対して滑らかな重み付け関数を定義している。

　これによって出力の質は大幅に改善されるが（図2(e)）、方向の特徴を捉えることができず、クラスタリングのアーチファクトが生じる。
我々のアプローチは、フィルタを入力の局所構造に適応させることで、これらの限界に対処する。
図2(f)を見ればわかるように、これによってクラスタリングが回避され、さらに方向性のある画像の特徴を絵画的に表現することができる。

図3：本手法と等方的アプローチとの比較：
(a) 長方形のサブ領域。1つのサブ領域のみが選択される。
(b) 円盤のセクターをサブ領域としたもの。複数のセクターが選択される。
(c) 局所構造に基づいて導出された異方性のあるフィルター形状。それがサブ領域に分割され、複数のフィルター応答が選択される。
※(a)、(b)、(c) の各サブ領域は、わずかに重なり合うように定義されている点に注意。

図4：本手法で使用されるフィルターカーネル（N=8）。
フィルターカーネルの形状と向きは、入力の局所構造に応じて調整されます。

　いくつかの古典的な手法は、画像の局所構造を考慮するように拡張することに成功している。
最も有名な例は、PeronaとMalikによる異方性拡散かもしれない[PM90]。
他の例としては、Yang et al. 
[YBFU96]では、エッジ保存スムージングに異方性ガウスカーネルが使われています。
Greenberg and Kogan [GK06]は、Yangらのアルゴリズムのガウシアンカーネルをメディアンフィルタに置き換えています。
のアルゴリズムにおけるガウシアンカーネルをメディアンフィルタで置き換え、フィルタカーネルに楕円形状を用いることを提案している。
Wangら[WTXC04]は、局所密度を推定するためにミーンシフトで使われる放射対称カーネルを、楕円形の異方性カーネルで置き換えている。

　画像の抽象化によく使われるフィルタにバイラテラルフィルタ[TM98]がある。Winnemöllerら[WOG06]は、バイラテラルフィルタ[PvV05]の分離可能な近似を色量子化と組み合わせて、リアルタイムで動画を抽象化している。
[KD08]では、バイラテラルフィルタの変形が提示されており、これは画像の局所構造にアライメントされている。このアライメントにより、ブロック・アーチファクトが回避され、色領域間の境界が滑らかに作られる。Kang et al. 
[KLC09]は、特徴フローフィールドによって導かれるバイラテラルフィルタの別の変形を提示し、特徴保存、ノイズ除去、スタイル化の点でフルカーネルバイラテラルフィルタを凌駕している。

　DeCarloとSantella[DS02,SD04]は、視線追跡データを使用して、異なるスケールでの平均シフト・セグメンテーション[CM02]に基づく画像の抽象化を導く。WXSC04]では、非等方的な平均シフト・セグメンテーション[WTXC04]が、動画をカートゥーン・アニメーションに変換するために使用されている。Collomosse et al. 
Collomosseら[CRH05]は、ミーンシフトセグメンテーションを使用して、絵画的、スケッチ的、カートゥーンシェーディングなど、静的な非フォトリアリスティックレンダリングスタイルを動画に拡張している。
平均シフトに基づいて高度に抽象化されたカラースケッチを作成するインタラクティブなシステムが[WLL06]で紹介されている。
図2(a)のような高コントラスト画像で失敗する以外に、平均シフト・アルゴリズムの限界は、それが滑らかな境界を生成しないことである（図9(d)）。したがって、結果として得られる領域境界は、通常、様式的な外観を得るために後処理を必要とする。

　最近発表された他の画像抽象化アプローチとしては、ARDECOと呼ばれるセグメンテーションに基づく画像ベクトル化システム[LL06]、勾配領域画像処理に基づく写真の構造保存操作[OBBT07]、制約平均曲率フローに基づく形状単純化画像抽象化[KL08]などがある。
[FFLS08]では、重み付き最小二乗法の枠組みに基づく、エッジを保存する平滑化オペレータと、その漸進的な画像抽象化への応用が紹介されている。これらの技法は大掛かりな処理を必要とし、動画への応用はテストされていない。


3. 方法
まず構造テンソルを計算し、ガウシアンフィルターで平滑化する。
局所方位と異方性の尺度は、平滑化された構造テンソルの固有値と固有ベクトルから導出する。
最後に非線形フィルタを用いて構造を考慮した平滑化を行う。
フィルタを用いて行われる。この非線形フィルターは、その形状は局所的な方位と異方性に基づいている（図4）。
フィルター応答は次のように定義される。標準偏差の低い平均値により多くの重みが与えられる。

3.1. 方向と異方性の推定
局所的な方向（オリエンテーション）と異方性（アニソトロピー）の推定は、構造テンソルの固有値および固有ベクトルに基づいています [BWBM06]。
本研究では、入力画像の RGB 値から直接、構造テンソルを計算します [KD08]。
ここで、関数 f:R 2 →R 3  は入力画像を表し、G σ,x  および G σ,y  は、標準偏差 σ を持つガウス関数の x および y 方向の空間微分を表します。

次に、関数 f の偏導関数の近似は、以下のようにして計算できます。

ここで、記号「*」は畳み込み（convolution）を表します。
関数 f の構造テンソル（structure tensor）は、次のように定義されます：

　ここで、「⟨ , ⟩」は**スカラー積（内積）**を表します。
構造テンソルの固有値は、変化率の最小値と最大値の2乗に対応しています。
固有ベクトルは、それぞれの変化方向に対応します。
変化率が最小となる固有ベクトルを選ぶことで、ベクトル場が得られます。
図 5(a) に示すように、このベクトル場には不連続性が含まれます。

このベクトル場を滑らかにするために、構造テンソル自体をガウスフィルタで平滑化します。
その結果が図 5(b) に示されています。
構造テンソルの平滑化はテンソルに対して線形な演算ですが、
固有ベクトルへの影響は非常に非線形であり、**幾何学的には主成分分析（PCA）**に相当します。

本研究の例では、標準偏差 σ=2.0 のガウスフィルタを使用しています。
なお、[WB05] などとは異なり、テンソルの正規化は行っていません。
そのため、勾配の大きいエッジに対応する構造テンソルは、平滑化時により大きな重みを持つことになります。
結果として、エッジの方向情報がその周辺領域にも伝播されることになります（図 5(c) 参照）。

　構造テンソルの固有値は非負の実数である。
の実数であり

変化率が最小となる方向に向いた固有ベクトルは、次のように与えられます：

ローカルな方向性を'D argt'と定義する。である。
異方性の量を測定するために、我々は [YBFU96]

異方性Aは0から1の範囲で、0は等方性、1は完全な異方性である。


3.2. 異方性桑原フィルタリング
　関数 f:R~2 →R~3を入力画像、点x 0 ∈R~2 を画像上の任意の位置とします。
また、φ をその位置における局所的な方向（オリエンテーション）、A を**異方性（アニソトロピー）**とします。
我々は、[Pha06] で提案された手法を用いて、楕円形のフィルター形状を定義します。
そして、異方性の大きさに応じて楕円の離心率（eccentricity）を調整するために、次のように設定します：

　パラメータ α>0 は調整用のパラメータです。
α→1 のとき、行列 S は単位行列に収束します。
本論文のすべての例では、α=1 を使用しており、これにより最大の離心率は 4 となります。
また、R ′を角度φ による回転を定義する回転行列とし、h=⌈ 2σr ⌉ とします（ここで σr  はガウス平滑化の半径、⌈⋅⌉ は切り上げ）。
このとき、集合：

　この式は、主軸が局所的な画像の方向に沿った楕円を定義します。
この楕円は、異方性の高い領域では細長くなり（高い離心率を持ち）、等方的な領域では円形になります。

　写像 SR′ は、領域 Ω を半径 h の円盤へ写す線形座標変換を定義します。
領域 Ω 上で重み関数を定義するために、まず円盤上に対応する重み関数を定義し、それを Ω へ引き戻します（pull back）。
円盤は、特徴関数を用いて定義される N 個の等しいセクターに分割されます。
特徴関数は、該当するセクター内では 1、それ以外では 0 を取ります。

　滑らかな重み関数を定義するために、各セクターの特徴関数 χi はまず畳み込み処理され、次にガウス関数と乗算されます。

図(1)

　畳み込みによって、特徴関数は滑らかになり、互いにわずかに重なり合うようになります。
また、ガウス関数との乗算によって、半径が大きくなるにつれて値が減衰する効果が得られます。
特徴関数 χi  は、回転行列 R 2πi/N による χ0  の関数合成として表され、ガウス関数は回転不変であるため、次の関係が成り立ちます：

　ここで、記号 ∘（合成記号）は関数の合成を意味します。
さらに、∑i​Ki​(x)=Gσr​(x) が x∈R~2 に対して成り立つため、関数 Ki の総和はガウスフィルタと等価になります。
この Ki を元の楕円領域 Ω に引き戻すことで、楕円領域上に定義された重み関数 wi を得ることができます。

図(2)

　次に、以下のように定義します

図(3)

重み付き局所平均を次のように定義します

図(4)

これを二乗された標準偏差とし、ここで k=∫wi(x−x0)dx は正規化係数を表します。
我々は次のように設定します。


そして、フィルターの出力を次のように定義します：

　我々が定義した重み係数 αi は、標準偏差が小さいセクター、すなわちより均質な領域に対して、より大きな重みが与えられることを保証します。
これは [PPC07] の手法（標準偏差 si に対して si−q を重みとして使う）と似ていますが、si が 0 の場合に不定になる問題を回避しています。
パラメータ q は、出力の鋭さ（シャープネス）を制御します。
我々の実験では q=8 を使用しました。
また、重み αi の定義では、入力画像の値が整数（例えば 8ビット画像なら 0～255 の範囲）で与えられていることを前提としています。


4. 実装

私たちは、提案するアルゴリズムを C++ と OpenGL Shading Language（GLSL） を用いて実装しました。

我々の実装では、式 (3) および (4) は 離散的な和によって近似されています。

図6：重み関数 K 0の近似（N=8 の場合）
(a) セクター特性関数 χ0
(b) 特性関数 χ0 をガウス関数 G σ sで畳み込み
(c) 最後にガウス関数 G σ r との積をとることで、半径に応じた減衰効果を得る

式 (2) は、重み関数 w i を計算するために使用されます。
重み関数 K 0 は、式 (1) をサンプリングしてテクスチャマップに変換することで近似され、そのテクスチャのサイズは (4h+2) 2 です。
図6(c) はそのテクスチャマップの構成を示しています。
このテクスチャマップのサンプリングには、後にバイリニア補間が使われます。

最適化手法
テクスチャの参照回数を削減するため、RGBAの4チャンネルテクスチャを使用しており、
K0, K1, K2, K3をそれぞれ 赤（R）・緑（G）・青（B）・アルファ（A） チャンネルに格納しています。
これにより、1回のテクスチャ参照で4つの重みを同時に取得できます。
さらに、楕円が対称性を持つことを利用して、テクスチャ参照の回数をさらに削減しています。

パフォーマンス
処理時間は以下に依存します：

・ガウス関数の標準偏差 σ r（＝フィルターカーネルの大きさ）
・セクター数 N
・入力画像のサイズ

解像度 512×512 の画像や DVD画質の映像では、nVidia Geforce GTX 280 上で 12 fps の処理速度を達成しました
（設定値：σ r​ =3.0, σ s​ =1.0, N=8）。
処理速度を向上させたい場合は、セクター数を N=4 に減らすことが考えられます。
ただし、これにより色領域間の境界がわずかにぼやける可能性があります。

色空間の選択
すべての計算は RGB色空間 で行っています。
CIE-Lab および CIE-LUV 色空間での実験も行いましたが、有意な差は見られませんでした。



5. 結果
図7 は、[PPC07] による 一般化 Kuwahara フィルタとの比較を示しています。
この従来手法では、等方的で固定されたフィルターカーネルのセットが使用されており、そのために小さな方向性のある画像特徴を捉えることができません。

さらに、カーネルの主方向があらかじめ定義されているため、形状の境界が十分に保持されないという問題があります。

Papari らの手法では、固定された等方性カーネルを使用しているため、ピクセルを円形のクラスターにまとめがちです。
この傾向は、さらなる抽象化を目指してフィルタを繰り返し適用した場合に顕著になります（図8を参照）。

これに対し、本論文の手法ではこの問題を回避し、複数回適用した後でも、特徴を保持したカラーパッチを生成できます。

図9 は、本手法が高コントラスト画像の抽象化にも有効であることを示しています。
バイラテラルフィルタは、高コントラストのディテールを抽象化するのが苦手であり、多くの細かくノイズの多い領域をそのまま残してしまいます（地面部分を参照）。

**平均値シフトセグメンテーション（Mean Shift Segmentation）**では、高次元空間での密度推定によって、不自然で粗い領域の境界が生じます。

一方、我々の手法は、ノイズのない、滑らかで一貫性のある抽象表現を画像全体にわたって実現します。

図10 は、バイラテラルフィルタが低コントラストの興味深い情報（猫の毛並みなど）を滑らかに消してしまい、高コントラストのディテール（口や鼻周辺の黒い斑点など）だけを残す一方で、
本手法では、一貫性があり特徴を強調した抽象表現が画像全体にわたって得られることを示しています。

図11 は、高コントラストノイズに対するバイラテラルフィルタの弱点をさらに明確に示しています。
この図では、入力画像に ガウスノイズおよびインパルスノイズを人工的に加えています。

本手法は画像をうまく復元し、視覚的に心地よい出力を生成します。
一方、フルカーネル型のバイラテラルフィルタよりもノイズに強いとされる Flow-based Bilateral Filter [KLC09, Pha06] であっても、高コントラストなインパルスノイズの除去には失敗しています。

我々は、本手法を動画抽象化にも適用し、各フレーム単体でのフィルタリングだけでも高い時間的整合性が得られることを確認しました。
そのため、動き推定 [Lit97, HE04] や 適応的なカラー量子化 [WOG06] などの追加処理は不要です。

本手法のGPU実装はリアルタイムで動画を処理することができ、絵画的な外観を与えるため、
[WOG06, KD08] などの バイラテラルフィルタベースの動画抽象化フレームワークの代替として有望です。

制限事項：
ただし、本手法には制限もあり、たとえば ゴッホの「星月夜（Starry Night）」のような粗く筆致のある油絵風表現には適していません。
このような強いテクスチャやブラシの効果を表現するには、背景の紙テクスチャや、方向性のある累積的なアルファマップ [Her02] を組み合わせる必要があります。



6. 結論
本研究では、異方性一般化 Kuwahara フィルタリングに基づく、画像および動画の自動抽象化手法を提案しました。
このフィルタは、平滑化された構造テンソルに基づいてガイドされ、特徴を保持しつつ、方向性を強調した絵画的な外観を生成します。
そのため、個々の筆致（ブラシストローク）を扱う必要がありません。
従来の非線形平滑化フィルタとは異なり、本手法は：

・高コントラストなノイズに対して堅牢であり、
・低コントラスト領域での過度なぼかしを回避し、
・画像全体にわたって一貫した抽象化レベルを提供します。

さらに、動画の抽象化においても高い時間的整合性（テンポラルコヒーレンス）を確保でき、各フレーム単体でのフィルタリングだけでも十分な品質が得られます。
本手法の GPUベースの実装は、動画をリアルタイムで処理可能です。